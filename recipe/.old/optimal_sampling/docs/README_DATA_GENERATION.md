# æœ€ä¼˜é‡‡æ ·æ•°æ®ç”Ÿæˆç®¡çº¿

åŸºäºæœ€ä¼˜é‡‡æ ·åˆ†å¸ƒ q* ç†è®ºçš„ RLHF æ•°æ®ç”Ÿæˆå·¥å…·ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- âœ… æ”¯æŒ **3ç§Alphaè®¡ç®—æ–¹æ³•**: fixed, kl_symmetry (ç†è®ºæœ€ä¼˜), entropy (å¿«é€Ÿè¿‘ä¼¼)
- âœ… æ”¯æŒ **2ç§Backend**: transformers (å®Œæ•´å®ç°), VLLM (è§„åˆ’ä¸­)
- âœ… **è‡ªåŠ¨æ•°æ®é›†é€‚é…**: è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†æ ¼å¼ï¼Œæ”¯æŒå¤šç§HuggingFaceæ•°æ®é›†
- âœ… **OpenAI APIæ ¼å¼è¾“å‡º**: messagesæ ¼å¼ï¼Œå¯ç›´æ¥ç”¨äºè®­ç»ƒ
- âœ… **å®Œæ•´è¯Šæ–­ä¿¡æ¯**: ESS ratio, KLæ•£åº¦, Alphaåˆ†å¸ƒç­‰
- âœ… **æ‰¹é‡ç”Ÿæˆ**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®ç”Ÿæˆå’Œæ–­ç‚¹ç»­ä¼ 

## ğŸ“¦ å®‰è£…

```bash
# å…‹éš†ä»“åº“ (å¦‚æœéœ€è¦)
cd optimal_sampling

# å®‰è£…ä¾èµ–
pip install -r requirements_data_generation.txt
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æµ‹è¯•ç®¡çº¿

```bash
# ä½¿ç”¨GPT-2å¿«é€Ÿæµ‹è¯•
python test_pipeline.py
```

### 2. ç”Ÿæˆæ•°æ®

```bash
# åŸºç¡€ä½¿ç”¨ - å›ºå®šalpha
python generate_data.py \
    --model_theta meta-llama/Llama-2-7b-hf \
    --dataset agentica-org/DeepScaleR-Preview-Dataset \
    --output data/generated.jsonl \
    --alpha_method fixed \
    --fixed_alpha 0.5 \
    --num_samples 1000 \
    --save_diagnostics

# ç†è®ºæœ€ä¼˜ - KLå¯¹ç§°
python generate_data.py \
    --model_theta meta-llama/Llama-2-7b-hf \
    --model_t meta-llama/Llama-2-7b-chat-hf \
    --dataset agentica-org/DeepScaleR-Preview-Dataset \
    --output data/generated_optimal.jsonl \
    --alpha_method kl_symmetry \
    --num_samples 1000 \
    --batch_size 4 \
    --save_diagnostics
```

### 3. åˆ†æç»“æœ

```bash
# åˆ†æè¯Šæ–­ä¿¡æ¯
python analyze_diagnostics.py data/generated.diagnostics.jsonl --output_dir analysis/

# å¯¹æ¯”ä¸åŒæ–¹æ³•
python analyze_diagnostics.py \
    data/generated_fixed.diagnostics.jsonl \
    data/generated_kl.diagnostics.jsonl \
    data/generated_entropy.diagnostics.jsonl
```

## ğŸ“š æ–‡æ¡£

- **[å®Œæ•´ä½¿ç”¨æŒ‡å—](DATA_GENERATION_GUIDE.md)** - è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜å’Œæœ€ä½³å®è·µ
- **[å®éªŒè®¾è®¡](experiment_design.md)** - å®Œæ•´çš„å®éªŒæ–¹æ¡ˆ
- **[ç†è®ºè¯æ˜](proof_final.md)** - q* çš„ç†è®ºæ¨å¯¼

## ğŸ—ï¸ æ¶æ„

```
optimal_sampling/
â”œâ”€â”€ optimal_sampling_model.py     # æ ¸å¿ƒæ¨¡å‹ç±»
â”‚   â”œâ”€â”€ AlphaComputer             # Alphaå‚æ•°è®¡ç®—
â”‚   â”œâ”€â”€ DiagnosticComputer        # è¯Šæ–­ä¿¡æ¯
â”‚   â””â”€â”€ OptimalSamplingModel      # ä¸»æ¨¡å‹
â”‚
â”œâ”€â”€ generate_data.py              # æ•°æ®ç”Ÿæˆè„šæœ¬
â”‚   â”œâ”€â”€ DatasetAdapter            # æ•°æ®é›†é€‚é…å™¨
â”‚   â””â”€â”€ DataGenerator             # æ•°æ®ç”Ÿæˆå™¨
â”‚
â”œâ”€â”€ analyze_diagnostics.py        # è¯Šæ–­åˆ†æå·¥å…·
â”œâ”€â”€ test_pipeline.py              # æµ‹è¯•è„šæœ¬
â””â”€â”€ DATA_GENERATION_GUIDE.md      # ä½¿ç”¨æŒ‡å—
```

## ğŸ”¬ Alphaè®¡ç®—æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | é€Ÿåº¦ | ç†è®ºä¿è¯ | æ¨èåœºæ™¯ |
|------|------|----------|----------|
| **fixed** | â­â­â­ | âŒ | å¿«é€Ÿæµ‹è¯• |
| **entropy** | â­â­ | è¿‘ä¼¼ | å¿«é€Ÿç”Ÿæˆå¤§è§„æ¨¡æ•°æ® |
| **kl_symmetry** | â­ | âœ… å®Œæ•´ | æœ€ç»ˆè®­ç»ƒæ•°æ® |

## ğŸ“Š è¾“å‡ºæ ¼å¼

### ä¸»æ•°æ®æ–‡ä»¶ (`.jsonl`)

```json
{
  "messages": [
    {"role": "user", "content": "What is AI?"},
    {"role": "assistant", "content": "AI is..."}
  ],
  "sample_idx": 0
}
```

### è¯Šæ–­æ–‡ä»¶ (`.diagnostics.jsonl`)

```json
{
  "sample_idx": 0,
  "alpha_mean": 0.523,
  "alpha_std": 0.045,
  "ess_ratio_mean": 0.987,
  "ess_ratio_std": 0.112,
  "kl_theta_mean": 0.234,
  "kl_t_mean": 0.231
}
```

## ğŸ¯ ç†è®ºéªŒè¯æŒ‡æ ‡

ç”Ÿæˆçš„æ•°æ®åº”æ»¡è¶³ï¼š

1. **ESS Ratio â‰ˆ 1.0** (åœ¨ [0.8, 1.2] èŒƒå›´å†…)
   - è¡¨ç¤ºFisherä¿¡æ¯å¹³è¡¡

2. **Alpha âˆˆ [0.2, 0.8]**
   - è¿‡äºæç«¯çš„alphaå¯èƒ½è¡¨ç¤ºåˆ†å¸ƒä¸åŒ¹é…

3. **KLå¯¹ç§°** (ä»…kl_symmetryæ–¹æ³•)
   - D_KL(q*||Ï€_Î¸) â‰ˆ D_KL(q*||Ï€_t)
   - å·®å¼‚åº” < 0.05

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

1. **å…ˆç”¨å°æ¨¡å‹æµ‹è¯•**: ä½¿ç”¨ `gpt2` æˆ– `--num_samples 10` éªŒè¯ç®¡çº¿
2. **ç›‘æ§è¯Šæ–­ä¿¡æ¯**: ä½¿ç”¨ `--save_diagnostics` è·Ÿè¸ªESS ratio
3. **æ‰¹é‡å¤§å°è°ƒæ•´**: æ ¹æ®GPUå†…å­˜è°ƒæ•´ `--batch_size`
4. **æ–­ç‚¹ç»­ä¼ **: ä½¿ç”¨ `--start_idx` ä»ä¸­æ–­å¤„ç»§ç»­

## ğŸ› å¸¸è§é—®é¢˜

**Q: CUDA out of memory?**
```bash
--batch_size 2 --dtype float16
```

**Q: ç”Ÿæˆé€Ÿåº¦æ…¢?**
```bash
--alpha_method entropy --batch_size 16
```

**Q: æ•°æ®é›†æ ¼å¼ä¸å…¼å®¹?**
```bash
--dataset_adapter generic --prompt_field your_field
```

è¯¦è§ [DATA_GENERATION_GUIDE.md](DATA_GENERATION_GUIDE.md)

## ğŸ“ˆ æ€§èƒ½å‚è€ƒ

åœ¨ A100 (80GB) ä¸Šçš„æ€§èƒ½å‚è€ƒï¼š

| æ¨¡å‹ | Batch Size | Alphaæ–¹æ³• | é€Ÿåº¦ (samples/min) |
|------|-----------|-----------|-------------------|
| GPT-2 | 16 | fixed | ~100 |
| LLaMA-7B | 8 | fixed | ~20 |
| LLaMA-7B | 4 | kl_symmetry | ~8 |
| LLaMA-13B | 4 | kl_symmetry | ~4 |

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æå‡ºé—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

## ğŸ“ å¼•ç”¨

å¦‚æœè¿™ä¸ªå·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{optimal_sampling_rlhf,
  title={Optimal Sampling Distribution for RLHF via Fisher Information Balance},
  author={Your Name},
  year={2024}
}
```

## ğŸ“„ è®¸å¯

MIT License

---

**å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿ** è¿è¡Œ `python test_pipeline.py` è¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼ ğŸš€
