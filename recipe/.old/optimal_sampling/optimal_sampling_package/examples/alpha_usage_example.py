#!/usr/bin/env python3
"""
Alpha å€¼ä¿å­˜åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Optimal Sampling çš„ alpha ä¿å­˜åŠŸèƒ½ã€‚

æ³¨æ„: è¿™ä¸ªç¤ºä¾‹å±•ç¤º API ç”¨æ³•ã€‚ç”±äºå½“å‰ vLLM V1 æ¶æ„é™åˆ¶ï¼Œ
åµŒå¥—åˆå§‹åŒ– theta model å¯èƒ½ä¼šé‡åˆ°é—®é¢˜ã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œ
OptimalSamplingOutput ä¼šåŒ…å« alpha_history å’Œ alpha_stats å­—æ®µã€‚
"""

from optimal_sampling import OptimalSamplingV1, OptimalSamplingOutput
import json


def example_basic_usage():
    """ç¤ºä¾‹ 1: åŸºæœ¬ç”¨æ³•"""
    print("=" * 80)
    print("ç¤ºä¾‹ 1: åŸºæœ¬ Alpha å€¼è®¿é—®")
    print("=" * 80)

    # æ¨¡æ‹Ÿä¸€ä¸ªå·²ç»ç”Ÿæˆçš„è¾“å‡ºï¼ˆå®é™…ä½¿ç”¨ä¸­ç”± generate() è¿”å›ï¼‰
    # å®é™…ä»£ç :
    # sampler = OptimalSamplingV1(...)
    # outputs = sampler.generate(prompts=["What is AI?"], max_tokens=50)

    # æ¨¡æ‹Ÿè¾“å‡ºæ•°æ®
    mock_output = OptimalSamplingOutput(
        generated_texts=["AI is artificial intelligence..."],
        generated_ids=[[23, 45, 67, ...]],
        num_tokens=[50],
        alpha_history=[[0.523, 0.518, 0.521, 0.519, 0.522] * 10],  # 50 ä¸ª alpha å€¼
        alpha_stats=[{
            "mean": 0.5206,
            "std": 0.0018,
            "min": 0.518,
            "max": 0.523,
            "count": 50
        }]
    )

    # è®¿é—® alpha history
    print("\nğŸ“Š Alpha History:")
    alpha_values = mock_output.alpha_history[0]
    print(f"  - ç”Ÿæˆçš„ token æ•°: {mock_output.num_tokens[0]}")
    print(f"  - Alpha å€¼æ•°é‡: {len(alpha_values)}")
    print(f"  - å‰ 10 ä¸ª alpha å€¼: {alpha_values[:10]}")

    # è®¿é—®ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ Alpha ç»Ÿè®¡:")
    stats = mock_output.alpha_stats[0]
    print(f"  - å¹³å‡å€¼: {stats['mean']:.4f}")
    print(f"  - æ ‡å‡†å·®: {stats['std']:.4f}")
    print(f"  - èŒƒå›´: [{stats['min']:.4f}, {stats['max']:.4f}]")
    print(f"  - æ ·æœ¬æ•°: {stats['count']}")


def example_batch_processing():
    """ç¤ºä¾‹ 2: æ‰¹é‡å¤„ç†"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 2: æ‰¹é‡è¯·æ±‚çš„ Alpha å€¼")
    print("=" * 80)

    # æ¨¡æ‹Ÿæ‰¹é‡è¾“å‡º
    mock_batch_output = OptimalSamplingOutput(
        generated_texts=[
            "Machine learning is...",
            "Deep learning uses...",
            "Reinforcement learning involves..."
        ],
        generated_ids=[[1, 2, 3]] * 3,
        num_tokens=[30, 45, 38],
        alpha_history=[
            [0.52] * 30,
            [0.51] * 45,
            [0.53] * 38,
        ],
        alpha_stats=[
            {"mean": 0.520, "std": 0.002, "min": 0.518, "max": 0.522, "count": 30},
            {"mean": 0.510, "std": 0.003, "min": 0.507, "max": 0.513, "count": 45},
            {"mean": 0.530, "std": 0.001, "min": 0.529, "max": 0.531, "count": 38},
        ]
    )

    print("\næ‰¹é‡ç”Ÿæˆç»“æœ:")
    for i in range(len(mock_batch_output.generated_texts)):
        print(f"\nè¯·æ±‚ {i+1}:")
        print(f"  Text: {mock_batch_output.generated_texts[i][:40]}...")
        print(f"  Tokens: {mock_batch_output.num_tokens[i]}")
        print(f"  Alpha count: {len(mock_batch_output.alpha_history[i])}")
        print(f"  Avg Alpha: {mock_batch_output.alpha_stats[i]['mean']:.4f}")


def example_save_to_file():
    """ç¤ºä¾‹ 3: ä¿å­˜åˆ°æ–‡ä»¶"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 3: ä¿å­˜ Alpha å€¼åˆ°æ–‡ä»¶")
    print("=" * 80)

    # æ‰‹åŠ¨åˆ›å»º JSON æ•°æ®ï¼ˆæ¼”ç¤ºæ ¼å¼ï¼‰
    alpha_data = {
        "num_requests": 2,
        "requests": [
            {
                "request_index": 0,
                "alpha_history": [0.52, 0.51, 0.53, 0.52, 0.51],
                "num_tokens": 5,
                "statistics": {
                    "mean": 0.518,
                    "std": 0.007,
                    "min": 0.51,
                    "max": 0.53,
                    "count": 5
                }
            },
            {
                "request_index": 1,
                "alpha_history": [0.54, 0.53, 0.52, 0.53],
                "num_tokens": 4,
                "statistics": {
                    "mean": 0.530,
                    "std": 0.007,
                    "min": 0.52,
                    "max": 0.54,
                    "count": 4
                }
            }
        ]
    }

    # ä¿å­˜åˆ°æ–‡ä»¶
    filepath = "example_alpha_history.json"
    with open(filepath, 'w') as f:
        json.dump(alpha_data, f, indent=2)

    print(f"\nâœ… Alpha å†å²å·²ä¿å­˜åˆ°: {filepath}")

    # è¯»å–å¹¶éªŒè¯
    with open(filepath, 'r') as f:
        loaded_data = json.load(f)

    print(f"\nğŸ“– æ–‡ä»¶å†…å®¹éªŒè¯:")
    print(f"  - è¯·æ±‚æ•°é‡: {loaded_data['num_requests']}")
    for req in loaded_data['requests']:
        print(f"\n  è¯·æ±‚ {req['request_index']}:")
        print(f"    - Alpha å€¼æ•°é‡: {len(req['alpha_history'])}")
        print(f"    - å¹³å‡å€¼: {req['statistics']['mean']:.4f}")

    # æ¸…ç†
    import os
    os.remove(filepath)
    print(f"\nâœ… æ¸…ç†ç¤ºä¾‹æ–‡ä»¶: {filepath}")


def example_alpha_analysis():
    """ç¤ºä¾‹ 4: Alpha å€¼åˆ†æ"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 4: Alpha å€¼åˆ†æ")
    print("=" * 80)

    # æ¨¡æ‹Ÿä¸åŒåœºæ™¯çš„ alpha å€¼
    scenarios = {
        "ç¨³å®šç”Ÿæˆ": [0.52] * 50,
        "é€æ¸å¢åŠ ": [0.50 + i * 0.001 for i in range(50)],
        "æ³¢åŠ¨è¾ƒå¤§": [0.52 if i % 2 == 0 else 0.48 for i in range(50)],
    }

    import numpy as np

    for name, alpha_values in scenarios.items():
        alpha_array = np.array(alpha_values)
        print(f"\nğŸ“Š åœºæ™¯: {name}")
        print(f"  - å¹³å‡å€¼: {np.mean(alpha_array):.4f}")
        print(f"  - æ ‡å‡†å·®: {np.std(alpha_array):.4f}")
        print(f"  - èŒƒå›´: [{np.min(alpha_array):.4f}, {np.max(alpha_array):.4f}]")

        # åˆ¤æ–­ç¨³å®šæ€§
        if np.std(alpha_array) < 0.01:
            print(f"  - ç¨³å®šæ€§: âœ… ç¨³å®š")
        elif np.std(alpha_array) < 0.02:
            print(f"  - ç¨³å®šæ€§: âš ï¸  ä¸­ç­‰")
        else:
            print(f"  - ç¨³å®šæ€§: âŒ æ³¢åŠ¨è¾ƒå¤§")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 80)
    print("ğŸ¨ Alpha å€¼ä¿å­˜åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 80)

    example_basic_usage()
    example_batch_processing()
    example_save_to_file()
    example_alpha_analysis()

    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ!")
    print("=" * 80)

    print("\nğŸ’¡ å®é™…ä½¿ç”¨æ–¹æ³•:")
    print("""
    from optimal_sampling import OptimalSamplingV1

    # 1. åˆå§‹åŒ–
    sampler = OptimalSamplingV1(
        model_teacher="Qwen/Qwen2.5-3B-Instruct",
        model_theta="Qwen/Qwen2.5-1.5B-Instruct",
        alpha_method="kl_symmetry",
        track_alpha_stats=True,  # å¼€å¯ alpha è¿½è¸ª
    )

    # 2. ç”Ÿæˆ
    outputs = sampler.generate(
        prompts=["What is AI?"],
        max_tokens=100,
        temperature=0.8,
    )

    # 3. è®¿é—® alpha å€¼
    if outputs.alpha_history:
        print(f"Alpha å€¼: {outputs.alpha_history[0][:10]}...")
        print(f"ç»Ÿè®¡: {outputs.alpha_stats[0]}")

    # 4. ä¿å­˜åˆ°æ–‡ä»¶
    sampler.save_alpha_history(outputs, "alpha.json")
    """)


if __name__ == '__main__':
    main()
