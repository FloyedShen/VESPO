#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯• Qwen3-4B-Base + Qwen3-14B
å‡è®¾ä¸¤ä¸ª vLLM å®ä¾‹å·²ç»åœ¨è¿è¡Œ
"""

import asyncio
import numpy as np
from coordinator_enhanced import EnhancedDualVLLMCoordinator
from config_enhanced import EnhancedCoordinatorConfig


async def test():
    """ç®€å•æµ‹è¯•"""
    print("\n" + "="*70)
    print("ğŸ§ª Qwen3-4B-Base + Qwen3-14B ç®€å•æµ‹è¯•")
    print("="*70)

    # é…ç½®
    config = EnhancedCoordinatorConfig(
        theta_url="http://localhost:9000",
        t_url="http://localhost:9001",
        top_k=20,  # vLLM 0.11.0 é™åˆ¶æœ€å¤§ä¸º 20
        force_first_token=True,
        constraint_to_target=True,
        target_top_p=0.95,
        enable_logging=False,
    )

    # æµ‹è¯•æç¤º
    prompts_theta = [
        "Q: What is machine learning?\nA:",
        "Q: Explain neural networks.\nA:",
    ]

    prompts_t = [
        "<|im_start|>user\nWhat is machine learning?<|im_end|>\n<|im_start|>assistant\n",
        "<|im_start|>user\nExplain neural networks.<|im_end|>\n<|im_start|>assistant\n",
    ]

    print(f"\nğŸ“ æµ‹è¯• {len(prompts_theta)} ä¸ªæç¤º...")
    print(f"   Base æ ¼å¼: {prompts_theta[0][:40]}...")
    print(f"   Instruct æ ¼å¼: {prompts_t[0][:40]}...")

    try:
        async with EnhancedDualVLLMCoordinator(config) as coordinator:
            results = await coordinator.generate_batch_dual_prompts(
                prompts_theta=prompts_theta,
                prompts_t=prompts_t,
                max_tokens=2000,
                temperature=1.0,
                return_diagnostics=True,
                show_progress=True
            )

            # åˆ†æç»“æœ
            print(f"\n{'='*70}")
            print("ğŸ“Š ç»“æœ")
            print("="*70)

            print(results)
            for i, result in enumerate(results):
                print(f"\n[{i+1}] {prompts_theta[i][:30]}...")

                if result.error:
                    print(f"  âŒ é”™è¯¯: {result.error}")
                else:
                    alpha_mean = np.mean(result.alpha_history)
                    alpha_std = np.std(result.alpha_history)

                    print(f"  âœ… Tokens: {len(result.generated_tokens)}")
                    print(f"  ğŸ“Š Î±: {alpha_mean:.3f} Â± {alpha_std:.3f}")
                    print(f"     é¦– Î±: {result.alpha_history[0]:.3f}")

                    if result.diagnostics:
                        print(f"  ğŸ“ˆ KL å¯¹ç§°è¯¯å·®: {result.diagnostics['kl_diff_mean']:.6f}")
                        print(f"     ESS æ¯”ä¾‹: {result.diagnostics['ess_ratio_mean']:.3f}")

            # ç»Ÿè®¡
            stats = coordinator.get_statistics()
            print(f"\n{'='*70}")
            print("ğŸ“ˆ ç»Ÿè®¡")
            print("="*70)
            print(f"  è¯·æ±‚æ•°: {stats['total_requests']}")
            print(f"  Token æ•°: {stats['total_tokens']}")
            print(f"  é¦– token å¼ºåˆ¶æ¬¡æ•°: {stats['first_token_forced']}")
            print(f"  çº¦æŸåº”ç”¨æ¬¡æ•°: {stats['constraint_applied']}")

            print("\n" + "="*70)
            print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
            print("="*70)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test())
