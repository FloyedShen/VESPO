# ä» IS Reshape è§†è§’é‡æ–°æ€è€ƒ SFTï¼šç†è®ºæ´è§ä¸ä¼˜åŒ–ç­–ç•¥

## 1. é—®é¢˜èƒŒæ™¯

### 1.1 åœºæ™¯è®¾å®š

æˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹å…¸å‹åœºæ™¯ï¼š
- æœ‰ä¸€ä¸ª **well-trained çš„åŸºç¡€æ¨¡å‹** $\pi_0$ï¼ˆä¾‹å¦‚ç»è¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒçš„ LLMï¼‰
- æœ‰ä¸€ä»½ **é«˜è´¨é‡ SFT æ•°æ®** $\mathcal{D} = \{(x_i, y_i)\}$ï¼ˆå·²æ¸…æ´—ï¼Œæˆ–æ¥è‡ª RFTï¼‰
- ç›®æ ‡ï¼šè®©æ¨¡å‹å­¦ä¼šæ•°æ®ä¸­çš„æ–°èƒ½åŠ›ï¼ŒåŒæ—¶**æœ€å°åŒ–å¯¹å·²æœ‰èƒ½åŠ›çš„ç ´å**

### 1.2 ä¼ ç»Ÿ SFT çš„é—®é¢˜

ä¼ ç»Ÿ SFT çš„ç›®æ ‡æ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼š
$$L_{\text{SFT}}(\theta) = \mathbb{E}_{(x,y) \sim \mathcal{D}}[\log \pi_\theta(y|x)]$$

æ ¹æ®æˆ‘ä»¬çš„ç»Ÿä¸€æ¡†æ¶ï¼ˆÂ§2.2ï¼‰ï¼Œè¿™ç­‰ä»·äºï¼š
$$\min_\theta D_{KL}(\mu \| \pi_\theta)$$

å…¶ä¸­ $\mu$ æ˜¯æ•°æ®åˆ†å¸ƒã€‚

**Forward KL çš„ mean-seeking ç‰¹æ€§**æ„å‘³ç€ï¼š
- $\pi_\theta$ ä¼šè¯•å›¾**è¦†ç›– Î¼ çš„æ‰€æœ‰æ¨¡å¼**
- å³ä½¿æŸäº›æ¨¡å¼ä¸ $\pi_0$ çš„å½“å‰èƒ½åŠ›ç›¸è·ç”šè¿œ
- ä¸ºäº†è¦†ç›–è¿™äº›"è¿œ"æ¨¡å¼ï¼Œæ¨¡å‹éœ€è¦å¤§å¹…è°ƒæ•´å‚æ•°
- è¿™ç§è°ƒæ•´ä¼šç ´å $\pi_0$ å·²æœ‰çš„èƒ½åŠ›ï¼ˆ**ç¾éš¾æ€§é—å¿˜**ï¼‰

### 1.3 æ ¸å¿ƒçŸ›ç›¾

| ä¼ ç»Ÿ SFT çš„è¡Œä¸º | æˆ‘ä»¬æƒ³è¦çš„è¡Œä¸º |
|----------------|---------------|
| è¦†ç›– Î¼ çš„æ‰€æœ‰æ¨¡å¼ | ä¼˜å…ˆå­¦ä¹ ä¸ $\pi_0$ æ¥è¿‘çš„æ¨¡å¼ |
| Mean-seeking | Mode-seekingï¼ˆåœ¨æŸç§æ„ä¹‰ä¸Šï¼‰ |
| å¯¹æ‰€æœ‰æ ·æœ¬å¹³ç­‰å¯¹å¾… | å¯¹"è¿‘"æ ·æœ¬ç»™äºˆæ›´é«˜æƒé‡ |
| å¯èƒ½å¯¼è‡´å¤§å¹…å‚æ•°å˜åŒ– | æœ€å°åŒ–å‚æ•°å˜åŒ– |
| ç¾éš¾æ€§é—å¿˜é£é™©é«˜ | ä¿ç•™å·²æœ‰èƒ½åŠ› |

---

## 2. ç†è®ºæ¡†æ¶çš„æ´è§

### 2.1 ä»ç»Ÿä¸€æ¢¯åº¦å…¬å¼å‡ºå‘

å›é¡¾æˆ‘ä»¬çš„æ ¸å¿ƒå®šä¹‰ï¼š
$$g(\theta) = \mathbb{E}_\mu\left[f(w) \cdot r(x,y) \cdot \nabla_\theta \log \pi_\theta(y|x)\right]$$

å…¶ä¸­ $w = \pi_\theta(y|x) / \mu(y|x)$ã€‚

**å…³é”®è§‚å¯Ÿ**ï¼šé‡è¦æ€§æƒé‡ $w$ æœ¬èº«å°±ç¼–ç äº†"$\pi_\theta$ ä¸ Î¼ çš„ç›¸ä¼¼åº¦"
- $w > 1$ï¼š$\pi_\theta$ æ¯” Î¼ æ›´å–œæ¬¢è¿™ä¸ªæ ·æœ¬ â†’ ä¸å½“å‰æ¨¡å‹"è¿‘"
- $w < 1$ï¼š$\pi_\theta$ æ¯” Î¼ æ›´ä¸å–œæ¬¢è¿™ä¸ªæ ·æœ¬ â†’ ä¸å½“å‰æ¨¡å‹"è¿œ"
- $w \approx 1$ï¼šä¸¤è€…å¯¹è¿™ä¸ªæ ·æœ¬çš„åå¥½ç›¸ä¼¼

### 2.2 f(w) çš„é€‰æ‹©å¦‚ä½•å½±å“å­¦ä¹ è¡Œä¸º

| f(w) | æƒé‡ç‰¹æ€§ | å­¦ä¹ è¡Œä¸º |
|------|---------|---------|
| f(w) = 1 | æ‰€æœ‰æ ·æœ¬ç­‰æƒ | è¦†ç›–æ‰€æœ‰æ¨¡å¼ï¼ˆä¼ ç»Ÿ SFTï¼‰ |
| f(w) = w | é«˜ w æ ·æœ¬æƒé‡å¤§ | èšç„¦äº $\pi_\theta$ å·²é«˜æ¦‚ç‡çš„æ ·æœ¬ |
| f(w) = $w^\gamma$ | ä»‹äºä¸¤è€…ä¹‹é—´ | å¯æ§çš„èšç„¦ç¨‹åº¦ |

**æ ¸å¿ƒæ´è§**ï¼š

> **å½“ Î³ > 0 æ—¶ï¼Œä¼˜åŒ–è‡ªç„¶åœ°ä»"è¦†ç›– Î¼"å˜æˆ"èšç„¦äº $\pi_\theta$ ä¸ Î¼ é‡å çš„éƒ¨åˆ†"ã€‚**

è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„è¡Œä¸ºï¼

### 2.3 ä¸ºä»€ä¹ˆè¿™èƒ½ç¼“è§£ç¾éš¾æ€§é—å¿˜ï¼Ÿ

è®¾å½“å‰æ¨¡å‹ä¸º $\pi_\theta$ï¼ˆåˆå§‹åŒ–ä¸º $\pi_0$ï¼‰ï¼Œè€ƒè™‘ä¸¤ç±»æ ·æœ¬ï¼š

**ç±»å‹ Aï¼šä¸ $\pi_0$ æ¥è¿‘çš„æ ·æœ¬**
- $\pi_0(y|x)$ è¾ƒé«˜ â†’ w è¾ƒå¤§ â†’ æƒé‡ $w^\gamma$ è¾ƒå¤§
- å­¦ä¹ è¿™äº›æ ·æœ¬åªéœ€è¦å°å¹…å‚æ•°è°ƒæ•´
- å¯¹å…¶ä»–èƒ½åŠ›å½±å“å°

**ç±»å‹ Bï¼šä¸ $\pi_0$ è¿œç¦»çš„æ ·æœ¬**
- $\pi_0(y|x)$ è¾ƒä½ â†’ w è¾ƒå° â†’ æƒé‡ $w^\gamma$ è¾ƒå°
- è¿™äº›æ ·æœ¬è¢«è‡ªåŠ¨é™æƒ
- ä¸å¼ºè¿«æ¨¡å‹å¤§å¹…è°ƒæ•´å‚æ•°

**ç»“æœ**ï¼šæ¨¡å‹ä¼˜å…ˆå­¦ä¹ "é¡ºå…¶è‡ªç„¶"çš„æ¨¡å¼ï¼Œè€Œéè¢«è¿«è¦†ç›–æ‰€æœ‰æ¨¡å¼ã€‚

### 2.4 ä¸ç›®æ ‡åˆ†å¸ƒçš„å…³ç³»

åœ¨çº¯ SFT åœºæ™¯ä¸‹ï¼ˆr â‰¡ 1ï¼‰ï¼Œä¸åŒ Î³ å¯¹åº”çš„æœ‰æ•ˆç›®æ ‡åˆ†å¸ƒï¼š

| Î³ | æœ‰æ•ˆç›®æ ‡åˆ†å¸ƒ | ç›´è§‰ |
|---|-------------|------|
| 0 | $\mu$ï¼ˆæ•°æ®åˆ†å¸ƒï¼‰ | å­¦ä¹ æ•°æ®çš„æ‰€æœ‰æ¨¡å¼ |
| 0.5 | $\propto \sqrt{\pi_\theta \cdot \mu}$ | å‡ ä½•å¹³å‡ï¼ŒæŠ˜ä¸­ |
| 1 | $\propto \pi_\theta$ï¼ˆè‡ªæˆ‘å¼ºåŒ–ï¼‰ | åªå¼ºåŒ–å·²æœ‰èƒ½åŠ› |

**å®è·µä¸­**ï¼Œæˆ‘ä»¬ä¸æƒ³èµ°åˆ° Î³ = 1ï¼ˆé‚£æ ·æ¨¡å‹ä¸å­¦æ–°ä¸œè¥¿ï¼‰ï¼Œè€Œæ˜¯é€‰æ‹©ä¸€ä¸ªä¸­é—´å€¼ï¼Œåœ¨"å­¦ä¹ æ–°çŸ¥è¯†"å’Œ"ä¿æŒå·²æœ‰èƒ½åŠ›"ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

---

## 3. å®è·µæ–¹æ¡ˆï¼šMode-Seeking SFT

### 3.1 æ–¹æ³•æ¦‚è¿°

**æ ¸å¿ƒæ€æƒ³**ï¼šç”¨ IS reshape æƒé‡æ›¿ä»£ä¼ ç»Ÿ SFT çš„ç­‰æƒé‡

**æŸå¤±å‡½æ•°**ï¼š
$$L_{\gamma}(\theta) = -\sum_i w_i^\gamma \cdot \log \pi_\theta(y_i|x_i)$$

å…¶ä¸­ï¼š
$$w_i = \frac{\pi_\theta(y_i|x_i)}{\mu_{\text{ref}}(y_i|x_i)}$$

### 3.2 å‚è€ƒåˆ†å¸ƒçš„é€‰æ‹©

**é—®é¢˜**ï¼šæˆ‘ä»¬æ²¡æœ‰çœŸå®çš„ $\mu$ï¼Œåªæœ‰æ•°æ®æ ·æœ¬ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šç”¨å‚è€ƒæ¨¡å‹ $\mu_{\text{ref}}$ è¿‘ä¼¼

| å‚è€ƒæ¨¡å‹é€‰æ‹© | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|-------------|------|------|
| $\pi_0$ï¼ˆåˆå§‹æ¨¡å‹ï¼‰ | ç®€å•ï¼Œè‡ªç„¶çš„"è·ç¦»"åº¦é‡ | éšç€è®­ç»ƒè¿›è¡Œï¼Œåº¦é‡å¯èƒ½ä¸å‡† |
| SFT checkpoint | æ›´æ¥è¿‘æ•°æ®åˆ†å¸ƒ | éœ€è¦é¢å¤–è®­ç»ƒä¸€ä¸ªæ¨¡å‹ |
| å†»ç»“çš„ $\pi_0$ | å›ºå®šå‚è€ƒï¼Œç¨³å®šçš„åº¦é‡ | æ¨è âœ“ |

**æ¨è**ï¼šä½¿ç”¨å†»ç»“çš„åˆå§‹æ¨¡å‹ $\pi_0$ ä½œä¸º $\mu_{\text{ref}}$ã€‚è¿™æ · $w = \pi_\theta / \pi_0$ åº¦é‡çš„æ˜¯"ç›¸å¯¹äºåˆå§‹æ¨¡å‹çš„å˜åŒ–"ã€‚

### 3.3 è‡ªé€‚åº” Î³ é€‰æ‹©

æ ¹æ®æˆ‘ä»¬çš„ç†è®ºï¼ˆÂ§10ï¼‰ï¼Œæœ€ä¼˜ Î³ å–å†³äºåˆ†å¸ƒåç§»ç¨‹åº¦ï¼š
$$\gamma^* = \max\left(0, 1 - \frac{\sigma^2}{2\delta}\right)$$

**å®è·µä¸­çš„ ESS è‡ªé€‚åº”æ–¹æ³•**ï¼š

```python
def adaptive_gamma(log_w, rho_min=0.3):
    """
    é€‰æ‹©æ»¡è¶³ ESS çº¦æŸçš„æœ€å¤§ Î³

    log_w: log(Ï€_Î¸ / Ï€_0) for each sample
    rho_min: æœ€å° ESS æ¯”ä¾‹
    """
    n = len(log_w)

    def compute_ess_ratio(gamma):
        weights = softmax(gamma * log_w)
        ess = 1.0 / sum(weights ** 2)
        return ess / n

    # äºŒåˆ†æœç´¢
    gamma_low, gamma_high = 0.0, 1.0
    while gamma_high - gamma_low > 1e-3:
        gamma_mid = (gamma_low + gamma_high) / 2
        if compute_ess_ratio(gamma_mid) >= rho_min:
            gamma_low = gamma_mid
        else:
            gamma_high = gamma_mid

    return gamma_low
```

### 3.4 å®Œæ•´ç®—æ³•

```python
def mode_seeking_sft(
    model,           # å¾…è®­ç»ƒæ¨¡å‹ Ï€_Î¸ï¼Œåˆå§‹åŒ–ä¸º Ï€_0
    ref_model,       # å‚è€ƒæ¨¡å‹ Ï€_0ï¼ˆå†»ç»“ï¼‰
    data,            # SFT æ•°æ®
    gamma=None,      # IS reshape å‚æ•°ï¼ˆNone åˆ™è‡ªé€‚åº”ï¼‰
    rho_min=0.3,     # ESS çº¦æŸ
    epochs=3
):
    """
    Mode-Seeking SFT: ä¼˜å…ˆå­¦ä¹ ä¸å½“å‰æ¨¡å‹æ¥è¿‘çš„æ¨¡å¼
    """
    for epoch in range(epochs):
        for batch in data:
            x, y = batch

            # è®¡ç®— log æ¦‚ç‡
            with torch.no_grad():
                log_pi_ref = ref_model.log_prob(y, x)
            log_pi = model.log_prob(y, x)

            # è®¡ç®— log é‡è¦æ€§æƒé‡
            log_w = log_pi - log_pi_ref

            # è‡ªé€‚åº”é€‰æ‹© Î³
            if gamma is None:
                gamma_batch = adaptive_gamma(log_w.detach(), rho_min)
            else:
                gamma_batch = gamma

            # è®¡ç®—å½’ä¸€åŒ–æƒé‡
            weights = F.softmax(gamma_batch * log_w.detach(), dim=0)

            # Mode-seeking SFT æŸå¤±
            loss = -torch.sum(weights * log_pi)

            # æ›´æ–°
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    return model
```

---

## 4. ç†è®ºåˆ†æï¼šä¸ºä»€ä¹ˆè¿™èƒ½å‡å°‘ç¾éš¾æ€§é—å¿˜

### 4.1 æ¢¯åº¦æ–¹å‘çš„æ”¹å˜

**ä¼ ç»Ÿ SFT çš„æ¢¯åº¦**ï¼š
$$g_{\text{SFT}} = \mathbb{E}_\mu[\nabla \log \pi_\theta]$$

è¿™ä¸ªæ¢¯åº¦æŒ‡å‘"è¦†ç›– Î¼ æ‰€æœ‰æ¨¡å¼"çš„æ–¹å‘ã€‚

**Mode-Seeking SFT çš„æ¢¯åº¦**ï¼š
$$g_\gamma = \mathbb{E}_\mu[w^\gamma \cdot \nabla \log \pi_\theta]$$

è¿™ä¸ªæ¢¯åº¦è¢«é‡æ–°åŠ æƒï¼ŒæŒ‡å‘"èšç„¦äº $\pi_\theta$ å·²é«˜æ¦‚ç‡æ ·æœ¬"çš„æ–¹å‘ã€‚

### 4.2 å‚æ•°å˜åŒ–é‡çš„å¯¹æ¯”

è®¾ $\Delta\theta$ ä¸ºå‚æ•°å˜åŒ–ã€‚ç›´è§‚ä¸Šï¼š

| æ–¹æ³• | å‚æ•°å˜åŒ–ç‰¹ç‚¹ |
|------|-------------|
| ä¼ ç»Ÿ SFT | éœ€è¦ç§»åŠ¨å‚æ•°ä»¥è¦†ç›–æ‰€æœ‰æ ·æœ¬ï¼ŒåŒ…æ‹¬è¿œç¦»çš„æ ·æœ¬ |
| Mode-Seeking SFT | ä¸»è¦ç§»åŠ¨å‚æ•°ä»¥æ›´å¥½åœ°æ‹Ÿåˆ"è¿‘"æ ·æœ¬ |

**é‡åŒ–åˆ†æ**ï¼šå‚æ•°å˜åŒ–é‡ä¸æ¢¯åº¦çš„äºŒé˜¶çŸ©ç›¸å…³ã€‚ç”±äº Mode-Seeking SFT é™ä½äº†"è¿œ"æ ·æœ¬çš„æƒé‡ï¼Œæ¢¯åº¦çš„æ–¹å·®æ›´å°ï¼Œå‚æ•°å˜åŒ–æ›´ç¨³å®šã€‚

### 4.3 ä¸ KL æ­£åˆ™åŒ–çš„è”ç³»

è®¸å¤š RLHF æ–¹æ³•ä½¿ç”¨ KL æ­£åˆ™åŒ–ï¼š
$$L = L_{\text{task}} + \beta \cdot D_{KL}(\pi_\theta \| \pi_0)$$

è¿™æ˜¾å¼åœ°æƒ©ç½šåç¦»åˆå§‹æ¨¡å‹ã€‚

**æˆ‘ä»¬çš„æ–¹æ³•ï¼ˆMode-Seeking SFTï¼‰æä¾›äº†ä¸€ä¸ªä¸åŒçš„è§†è§’**ï¼š
- ä¸æ˜¯æ˜¾å¼åœ°æƒ©ç½šåç¦»
- è€Œæ˜¯é€šè¿‡æ ·æœ¬åŠ æƒï¼Œéšå¼åœ°è®©ä¼˜åŒ–èšç„¦äº"è¿‘"æ¨¡å¼
- ä¸¤ç§æ–¹æ³•å¯ä»¥ç»“åˆä½¿ç”¨

---

## 5. ä¸ç°æœ‰æ–¹æ³•çš„å…³ç³»å’Œæ¯”è¾ƒ

### 5.1 æ–¹æ³•å¯¹æ¯”è¡¨

| æ–¹æ³• | æ ¸å¿ƒæ€æƒ³ | ä¸ IS Reshape çš„å…³ç³» |
|------|---------|---------------------|
| **ä¼ ç»Ÿ SFT** | æœ€å¤§ä¼¼ç„¶ | f(w)=1, râ‰¡1 |
| **å¥–åŠ±åŠ æƒ SFT** | é«˜å¥–åŠ±æ ·æœ¬æƒé‡å¤§ | f(w)=1, r=reward |
| **Mode-Seeking SFT**ï¼ˆæœ¬æ–‡ï¼‰ | è¿‘æ¨¡å¼ä¼˜å…ˆ | f(w)=w^Î³, râ‰¡1 |
| **DPO** | å¯¹æ¯”å­¦ä¹  | éšå¼çš„ mode-seeking |
| **KL æ­£åˆ™åŒ–** | æƒ©ç½šåç¦» | ä¸ mode-seeking äº’è¡¥ |
| **LoRA/PEFT** | é™åˆ¶å‚æ•°æ›´æ–° | æ­£äº¤æ–¹æ³•ï¼Œå¯ç»“åˆ |
| **Replay** | æ··åˆæ—§æ•°æ® | æ­£äº¤æ–¹æ³•ï¼Œå¯ç»“åˆ |

### 5.2 ä¸ DPO çš„æ·±å±‚è”ç³»

DPO çš„ç›®æ ‡å‡½æ•°ï¼š
$$L_{DPO} = -\log \sigma\left(\beta \log \frac{\pi_\theta(y_w)}{\pi_0(y_w)} - \beta \log \frac{\pi_\theta(y_l)}{\pi_0(y_l)}\right)$$

**å…³é”®è§‚å¯Ÿ**ï¼šDPO ä¸­ $\log \frac{\pi_\theta}{\pi_0}$ æ­£æ˜¯æˆ‘ä»¬çš„ log wï¼

DPO éšå¼åœ°å®ç°äº† mode-seekingï¼š
- ä¼˜å…ˆå¢åŠ é‚£äº›"å·²ç»ç›¸å¯¹é«˜æ¦‚ç‡"çš„å¥½æ ·æœ¬çš„æ¦‚ç‡
- é™ä½"å·²ç»ç›¸å¯¹ä½æ¦‚ç‡"çš„åæ ·æœ¬çš„æ¦‚ç‡

**æˆ‘ä»¬çš„æ–¹æ³•ä¸ DPO çš„åŒºåˆ«**ï¼š
- DPO éœ€è¦åå¥½å¯¹ (y_w, y_l)
- Mode-Seeking SFT åªéœ€è¦æ­£æ ·æœ¬
- ä¸¤è€…éƒ½åˆ©ç”¨äº† w = Ï€_Î¸/Ï€_0 çš„ä¿¡æ¯

### 5.3 ä¸è¯¾ç¨‹å­¦ä¹ çš„è”ç³»

Mode-Seeking SFT å¯ä»¥çœ‹ä½œä¸€ç§**éšå¼çš„è¯¾ç¨‹å­¦ä¹ **ï¼š
- è®­ç»ƒåˆæœŸï¼Œå¤§éƒ¨åˆ†æ ·æœ¬ w â‰ˆ 1ï¼Œå­¦ä¹ è¾ƒå‡åŒ€
- éšç€è®­ç»ƒï¼Œæ¨¡å‹å¼€å§‹åˆ†åŒ–ï¼Œè‡ªåŠ¨èšç„¦äº"æ“…é•¿"çš„æ ·æœ¬
- å›°éš¾/è¿œç¦»çš„æ ·æœ¬è¢«è‡ªåŠ¨æ¨è¿Ÿæˆ–é™æƒ

---

## 6. å®è·µå»ºè®®ä¸æœ€ä½³å®è·µ

### 6.1 ä½•æ—¶ä½¿ç”¨ Mode-Seeking SFT

**æ¨èä½¿ç”¨çš„åœºæ™¯**ï¼š
- åœ¨ well-trained æ¨¡å‹ä¸Šåšé¢†åŸŸå¾®è°ƒ
- å¸Œæœ›å­¦ä¹ æ–°èƒ½åŠ›çš„åŒæ—¶ä¿æŒé€šç”¨èƒ½åŠ›
- SFT æ•°æ®é‡è¾ƒå°ï¼Œæ‹…å¿ƒè¿‡æ‹Ÿåˆæˆ–é—å¿˜
- æ•°æ®è´¨é‡é«˜ä½†é£æ ¼å¤šæ ·ï¼ˆä¸æƒ³è¦†ç›–æ‰€æœ‰é£æ ¼ï¼‰

**ä¸æ¨èä½¿ç”¨çš„åœºæ™¯**ï¼š
- ä»å¤´è®­ç»ƒï¼ˆæ­¤æ—¶åº”è¯¥è¦†ç›–æ‰€æœ‰æ¨¡å¼ï¼‰
- æ•°æ®é‡å¾ˆå¤§ä¸”åŒè´¨ï¼ˆä¼ ç»Ÿ SFT è¶³å¤Ÿï¼‰
- éœ€è¦æ¨¡å‹å­¦ä¹ ä¸å½“å‰èƒ½åŠ›å®Œå…¨ä¸åŒçš„æ–°æŠ€èƒ½

### 6.2 è¶…å‚æ•°é€‰æ‹©æŒ‡å—

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|-------|------|
| Î³ï¼ˆå›ºå®šï¼‰ | 0.3 - 0.7 | è¶Šå¤§è¶Š mode-seeking |
| Î³ï¼ˆè‡ªé€‚åº”ï¼‰ | ç”± ESS å†³å®š | æ¨è |
| Ï_minï¼ˆESS æ¯”ä¾‹ï¼‰ | 0.2 - 0.5 | è¶Šå°å…è®¸è¶Šæ¿€è¿›çš„ IS |
| å­¦ä¹ ç‡ | æ­£å¸¸æˆ–ç•¥ä½ | é…åˆ mode-seeking å‡å°‘æ³¢åŠ¨ |

### 6.3 ä¸å…¶ä»–æ–¹æ³•çš„ç»“åˆ

**æ¨èç»„åˆ**ï¼š

1. **Mode-Seeking SFT + LoRA**
   - LoRA é™åˆ¶å‚æ•°å˜åŒ–çš„ç»´åº¦
   - Mode-Seeking é™åˆ¶æ ·æœ¬å½±å“çš„åˆ†å¸ƒ
   - åŒé‡ä¿æŠ¤ï¼Œæ•ˆæœæœ€å¥½

2. **Mode-Seeking SFT + KL æ­£åˆ™åŒ–**
   ```python
   loss = mode_seeking_loss + beta * kl_divergence(pi_theta, pi_0)
   ```
   - åŒé‡çº¦æŸï¼šæ ·æœ¬åŠ æƒ + æ˜¾å¼æƒ©ç½š

3. **Mode-Seeking SFT + æ•°æ®æ··åˆ**
   - åœ¨ SFT æ•°æ®ä¸­æ··å…¥å°‘é‡é€šç”¨æ•°æ®
   - Mode-Seeking ç¡®ä¿æ–°æ•°æ®ä¸ä¼šå‹å€’æ—§èƒ½åŠ›

### 6.4 ç›‘æ§æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç›‘æ§ï¼š

1. **ESS æ¯”ä¾‹**ï¼š$\rho = \text{ESS}/n$
   - è¿‡ä½ï¼ˆ< 0.1ï¼‰ï¼šÎ³ è¿‡å¤§ï¼Œå®é™…åªå­¦å°‘æ•°æ ·æœ¬
   - é€‚ä¸­ï¼ˆ0.2-0.5ï¼‰ï¼šç†æƒ³èŒƒå›´
   - è¿‡é«˜ï¼ˆ> 0.8ï¼‰ï¼šæ¥è¿‘æ™®é€š SFT

2. **æƒé‡åˆ†å¸ƒ**ï¼šè§‚å¯Ÿ $w^\gamma$ çš„åˆ†å¸ƒ
   - åº”è¯¥æ˜¯å³åä½†ä¸è¿‡åº¦é›†ä¸­

3. **éªŒè¯æŸå¤±**ï¼šåœ¨æ—§ä»»åŠ¡ä¸Šçš„æ€§èƒ½
   - åº”è¯¥ä¿æŒç¨³å®šæˆ–å°å¹…ä¸‹é™

---

## 7. æ‰©å±•æ€è€ƒ

### 7.1 Per-Sample Î³

ä¸åŒæ ·æœ¬å¯èƒ½éœ€è¦ä¸åŒçš„ Î³ï¼š
- ä¸ $\pi_0$ å¾ˆè¿‘çš„æ ·æœ¬ï¼šå¯ä»¥ç”¨è¾ƒå¤§çš„ Î³ï¼ˆå¼ºåŒ–ï¼‰
- ä¸ $\pi_0$ å¾ˆè¿œçš„æ ·æœ¬ï¼šå¯èƒ½éœ€è¦è¾ƒå°çš„ Î³ï¼ˆéœ€è¦å­¦ä¹ ï¼‰

$$\gamma_i = g(\text{distance}_i)$$

å…¶ä¸­ distance å¯ä»¥ç”¨ $-\log \pi_0(y_i|x_i)$ æˆ– KL æ•£åº¦åº¦é‡ã€‚

### 7.2 åŠ¨æ€ Î³ è°ƒåº¦

è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´ Î³ï¼š
- åˆæœŸï¼šÎ³ è¾ƒå°ï¼Œå¹¿æ³›å­¦ä¹ 
- ä¸­æœŸï¼šÎ³ å¢å¤§ï¼Œå¼€å§‹èšç„¦
- åæœŸï¼šÎ³ è¾ƒå¤§ï¼Œç²¾ç»†æ‰“ç£¨

ç±»ä¼¼äºå­¦ä¹ ç‡è°ƒåº¦ï¼Œä½†ä½œç”¨äºæ ·æœ¬æƒé‡ã€‚

### 7.3 ä¸ä¸»åŠ¨å­¦ä¹ çš„ç»“åˆ

Mode-Seeking SFT çš„æƒé‡å¯ä»¥æŒ‡å¯¼æ•°æ®é€‰æ‹©ï¼š
- ä½ w æ ·æœ¬ï¼šæ¨¡å‹ä¸æ“…é•¿ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç±»ä¼¼æ ·æœ¬
- é«˜ w æ ·æœ¬ï¼šæ¨¡å‹å·²æ“…é•¿ï¼Œå¯ä»¥å‡å°‘é‡‡æ ·

è¿™å¯ä»¥ç”¨äºè¿­ä»£çš„æ•°æ®æ”¶é›†å’Œè®­ç»ƒã€‚

---

## 8. Sequence-level ä¸ Token-level ç›®æ ‡çš„å…³ç³»

### 8.1 é—®é¢˜èƒŒæ™¯

æˆ‘ä»¬çš„ç»Ÿä¸€æ¡†æ¶åœ¨ **sequence level** å®šä¹‰ï¼š
$$g(\theta) = \mathbb{E}_\mu\left[f(w) \cdot r \cdot \nabla_\theta \log \pi_\theta(y|x)\right]$$

å…¶ä¸­ $w = \pi_\theta(y|x) / \mu(y|x)$ æ˜¯**åºåˆ—çº§åˆ«**çš„é‡è¦æ€§æƒé‡ã€‚

ç„¶è€Œï¼ŒLLM æ˜¯ token-by-token ç”Ÿæˆçš„ï¼š
$$\pi_\theta(y|x) = \prod_{t=1}^{|y|} \pi_\theta(y_t|x, y_{<t})$$

**æ ¸å¿ƒé—®é¢˜**ï¼šåœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ token-level çš„å®ç°æ¥ä¼˜åŒ– sequence-level çš„ç›®æ ‡ï¼Ÿ

### 8.2 ä¸€é˜¶è¿‘ä¼¼ç†è®º

**å…³é”®æ´è§**ï¼ˆå‚è€ƒ Qwen å›¢é˜Ÿçš„å·¥ä½œï¼‰ï¼šToken-level ç›®æ ‡å¯ä»¥çœ‹ä½œ sequence-level ç›®æ ‡çš„**ä¸€é˜¶è¿‘ä¼¼**ã€‚

**æ¨å¯¼**ï¼šè®¾ $\delta_t = \frac{\pi_\theta(y_t|x,y_{<t})}{\mu(y_t|x,y_{<t})} - 1$ æ˜¯æ¯ä¸ª token çš„é‡è¦æ€§æ¯”ç‡åç§»é‡ã€‚

å½“ $\delta_t$ è¾ƒå°æ—¶ï¼ˆå³ $\pi_\theta \approx \mu$ï¼‰ï¼š

$$w = \frac{\pi_\theta(y|x)}{\mu(y|x)} = \prod_{t=1}^{|y|}(1 + \delta_t) \approx 1 + \sum_{t=1}^{|y|}\delta_t + O(\delta^2)$$

å¿½ç•¥äºŒé˜¶åŠæ›´é«˜é˜¶é¡¹ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š

$$w \approx 1 + \sum_{t=1}^{|y|}\delta_t = \sum_{t=1}^{|y|}\frac{\pi_\theta(y_t|x,y_{<t})}{\mu(y_t|x,y_{<t})}$$

**ç»“è®º**ï¼šåºåˆ—çº§é‡è¦æ€§æƒé‡å¯ä»¥è¿‘ä¼¼ä¸º token çº§é‡è¦æ€§æƒé‡ä¹‹å’Œã€‚

### 8.3 å¯¹ Mode-Seeking SFT çš„æ„ä¹‰

åœ¨æˆ‘ä»¬çš„ Mode-Seeking SFT ä¸­ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š
$$L_\gamma(\theta) = -\sum_i w_i^\gamma \cdot \log \pi_\theta(y_i|x_i)$$

**Token-level è¿‘ä¼¼**ï¼šå½“ $\gamma$ è¾ƒå°ä¸” $\pi_\theta \approx \mu$ æ—¶ï¼š

$$w^\gamma \approx \left(1 + \sum_t \delta_t\right)^\gamma \approx 1 + \gamma \sum_t \delta_t$$

è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç”¨ token-level çš„æƒé‡å’Œæ¥è¿‘ä¼¼ sequence-level çš„æƒé‡ã€‚

### 8.4 è¿‘ä¼¼æœ‰æ•ˆçš„æ¡ä»¶

ä¸€é˜¶è¿‘ä¼¼æˆç«‹éœ€è¦æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼š

| æ¡ä»¶ | å«ä¹‰ | å¦‚ä½•æ»¡è¶³ |
|-----|------|---------|
| **Training-Inference ä¸€è‡´æ€§** | è®­ç»ƒå¼•æ“ä¸æ¨ç†å¼•æ“çš„æ•°å€¼è®¡ç®—ä¸€è‡´ | ä½¿ç”¨ç›¸åŒç²¾åº¦ã€ç›¸åŒ kernel |
| **Policy Staleness è¾ƒå°** | rollout ç­–ç•¥ä¸å½“å‰ç­–ç•¥æ¥è¿‘ | æ§åˆ¶ off-policy ç¨‹åº¦ã€ä½¿ç”¨ clipping |

**å¯¹äº MoE æ¨¡å‹çš„ç‰¹æ®ŠæŒ‘æˆ˜**ï¼š
- Expert routing å¯èƒ½åœ¨è®­ç»ƒå’Œæ¨ç†æ—¶ä¸ä¸€è‡´
- è§£å†³æ–¹æ¡ˆï¼šRouting Replayï¼ˆå›ºå®š expert è·¯ç”±ï¼‰

### 8.5 å®è·µå»ºè®®

**1. ç›‘æ§ $\delta_t$ çš„å¤§å°**ï¼š

```python
def monitor_token_delta(log_pi, log_mu):
    """ç›‘æ§ token-level çš„åç§»é‡"""
    delta = torch.exp(log_pi - log_mu) - 1
    return {
        'mean_abs_delta': delta.abs().mean().item(),
        'max_abs_delta': delta.abs().max().item(),
        'std_delta': delta.std().item(),
    }
```

- å½“ `mean_abs_delta > 0.5` æ—¶ï¼Œä¸€é˜¶è¿‘ä¼¼å¯èƒ½å¤±æ•ˆ
- å»ºè®®é€šè¿‡å‡å°å­¦ä¹ ç‡æˆ–å¢åŠ  clipping æ¥æ§åˆ¶

**2. Clipping ç­–ç•¥**ï¼š

å‚è€ƒ PPO é£æ ¼çš„ clippingï¼Œé˜²æ­¢å•æ­¥æ›´æ–°è¿‡å¤§ï¼š

```python
def clipped_weight(log_pi, log_pi_old, epsilon_low=0.2, epsilon_high=0.27):
    """Clip token-level æƒé‡ä»¥æ§åˆ¶ policy staleness"""
    ratio = torch.exp(log_pi - log_pi_old)
    clipped_ratio = torch.clamp(ratio, 1 - epsilon_low, 1 + epsilon_high)
    return clipped_ratio
```

**3. å¯¹äº MoE æ¨¡å‹**ï¼š

å»ºè®®ä½¿ç”¨ Routing Replayï¼š
- **R2 (Vanilla Routing Replay)**ï¼šé‡æ”¾è®­ç»ƒå¼•æ“çš„ expert routingï¼Œå‡å°‘ policy staleness
- **R3 (Rollout Routing Replay)**ï¼šé‡æ”¾æ¨ç†å¼•æ“çš„ expert routingï¼ŒåŒæ—¶å‡å°‘ training-inference å·®å¼‚å’Œ policy staleness

### 8.6 ä¸ä¸»æ¡†æ¶çš„è”ç³»

| å±‚çº§ | ç†è®ºå®šä¹‰ | å®é™…å®ç° | è¿‘ä¼¼æ¡ä»¶ |
|-----|---------|---------|---------|
| Sequence-level | $w = \pi_\theta(y|x)/\mu(y|x)$ | éœ€è¦å®Œæ•´åºåˆ—æ¦‚ç‡ | ç²¾ç¡® |
| Token-level | $\approx \sum_t \pi_\theta(y_t)/\mu(y_t)$ | é€ token è®¡ç®— | $\pi_\theta \approx \mu$ |

**å®è·µæŒ‡å¯¼**ï¼š
- å½“ Î³ è¾ƒå°ï¼ˆå¦‚ Î³ < 0.5ï¼‰æ—¶ï¼Œtoken-level å®ç°é€šå¸¸è¶³å¤Ÿå‡†ç¡®
- å½“ Î³ è¾ƒå¤§æˆ–åˆ†å¸ƒåç§»ä¸¥é‡æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨ sequence-level æƒé‡æˆ–å¢åŠ çº¦æŸ

---

## 9. ç›´æ¥æ±‚è§£çš„è¿‘ä¼¼æ–¹æ³•

### 9.1 è¿­ä»£æ±‚è§£çš„é—®é¢˜

æ ‡å‡†çš„ IS Reshape ä¼˜åŒ–é‡‡ç”¨ç­–ç•¥æ¢¯åº¦è¿­ä»£æ›´æ–°ï¼š

$$\theta_{t+1} = \theta_t + \eta \cdot \mathbb{E}_\mu\left[f(w) \cdot r \cdot \nabla_\theta \log \pi_\theta\right]$$

**å­˜åœ¨çš„é—®é¢˜**ï¼š
1. æ¯æ­¥éœ€è¦è®¡ç®—å½“å‰ç­–ç•¥çš„æ¦‚ç‡ï¼Œè®¡ç®—å¼€é”€å¤§
2. éœ€è¦å¤šæ¬¡è¿­ä»£æ‰èƒ½æ”¶æ•›
3. è¶…å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€è¿­ä»£æ¬¡æ•°ï¼‰æ•æ„Ÿ
4. åœ¨ offline åœºæ™¯ä¸‹ï¼Œæ— æ³•ä¸ç¯å¢ƒäº¤äº’æ¥ä¿®æ­£ off-policy è¯¯å·®

**æ ¸å¿ƒé—®é¢˜**ï¼šèƒ½å¦æ‰¾åˆ°è¿‘ä¼¼æ–¹æ³•ï¼Œç›´æ¥ï¼ˆæˆ–è¿‘ä¼¼ç›´æ¥ï¼‰æ±‚å‡ºæœ€ä¼˜ç­–ç•¥ï¼Œé¿å…è¿­ä»£ï¼Ÿ

### 9.2 ç†è®ºåŸºç¡€ï¼šæœ€ä¼˜åˆ†å¸ƒçš„é—­å¼è§£

#### 9.2.1 KL æ•£åº¦çº¦æŸä¸‹çš„æœ€ä¼˜è§£

è€ƒè™‘ä¼˜åŒ–é—®é¢˜ï¼š
$$\max_\pi \mathbb{E}_\pi[r] - \beta \cdot D_{KL}(\pi \| \mu)$$

è¿™æœ‰è§£æè§£ï¼š
$$\pi^*(y|x) = \frac{1}{Z} \mu(y|x) \cdot \exp\left(\frac{r(x,y)}{\beta}\right)$$

å…¶ä¸­ $Z = \mathbb{E}_\mu[\exp(r/\beta)]$ æ˜¯å½’ä¸€åŒ–å¸¸æ•°ã€‚

#### 9.2.2 Î±-æ•£åº¦çº¦æŸä¸‹çš„æœ€ä¼˜è§£

å¯¹äºå¹¿ä¹‰çš„ Î±-æ•£åº¦ï¼ˆå¯¹åº” IS Reshape çš„ f(w) = w^Î³ï¼Œå…¶ä¸­ Î³ = 1-Î±ï¼‰ï¼š

$$\pi^*_\alpha(y|x) \propto \mu(y|x) \cdot \left[1 + \frac{\alpha}{\beta} r(x,y)\right]_+^{1/\alpha}$$

å½“ $\alpha \to 0$ æ—¶ï¼Œé€€åŒ–ä¸º KL æƒ…å†µçš„æŒ‡æ•°å½¢å¼ã€‚

**å…³é”®æ´è§**ï¼šå¦‚æœæˆ‘ä»¬èƒ½ç›´æ¥åˆ©ç”¨è¿™äº›é—­å¼è§£ï¼Œå°±ä¸éœ€è¦è¿­ä»£ï¼

### 9.3 è¿‘ä¼¼æ–¹æ³•ä¸€ï¼šå¥–åŠ±åŠ æƒå›å½’ (Reward-Weighted Regression)

#### 9.3.1 æ ¸å¿ƒæ€æƒ³

æ—¢ç„¶æœ€ä¼˜åˆ†å¸ƒæœ‰å½¢å¼ $\pi^* \propto \mu \cdot g(r)$ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨åŠ æƒ MLE æ¥æ‹Ÿåˆï¼š

$$\theta^* = \arg\max_\theta \sum_i g(r_i) \cdot \log \pi_\theta(y_i|x_i)$$

å…¶ä¸­ $g(r)$ æ˜¯å¥–åŠ±å˜æ¢å‡½æ•°ã€‚

#### 9.3.2 å¸¸è§çš„ g(r) é€‰æ‹©

| æ–¹æ³• | g(r) | å¯¹åº”ç›®æ ‡ |
|-----|------|---------|
| **æŒ‡æ•°æƒé‡** | $\exp(r/\beta)$ | KL çº¦æŸçš„æœ€ä¼˜è§£ |
| **æˆªæ–­æŒ‡æ•°** | $\exp(\min(r, r_{\max})/\beta)$ | æœ‰ç•Œ KL çº¦æŸ |
| **å¹‚å‡½æ•°** | $(r - r_{\min})^\alpha$ | è¿‘ä¼¼ Î±-æ•£åº¦ |
| **Top-K æŒ‡ç¤ºå™¨** | $\mathbb{1}[r \in \text{top-K}]$ | æœ€ç®€å•çš„è¿‘ä¼¼ |
| **ä¼˜åŠ¿å½’ä¸€åŒ–** | $\exp((r-\bar{r})/\sigma_r)$ | è‡ªé€‚åº”ç¼©æ”¾ |

#### 9.3.3 å®ç°

```python
def reward_weighted_regression(
    model,
    data,  # [(x_i, y_i, r_i)]
    beta: float = 1.0,
    reward_transform: str = "exp",  # "exp", "power", "topk"
    topk_ratio: float = 0.2,
    num_epochs: int = 1,
):
    """
    ç›´æ¥æ±‚è§£ï¼šç”¨å¥–åŠ±åŠ æƒçš„ MLE æ‹Ÿåˆæœ€ä¼˜åˆ†å¸ƒ

    ä¼˜ç‚¹ï¼šæ— éœ€è¿­ä»£çš„ç­–ç•¥æ¢¯åº¦ï¼Œå•è½®è®­ç»ƒå³å¯
    """

    # è®¡ç®—æƒé‡
    rewards = torch.tensor([r for _, _, r in data])

    if reward_transform == "exp":
        # æ ‡å‡†æŒ‡æ•°æƒé‡
        weights = torch.softmax(rewards / beta, dim=0)
    elif reward_transform == "power":
        # å¹‚å‡½æ•°æƒé‡ï¼ˆå¯¹åº” Î±-æ•£åº¦ï¼‰
        r_shifted = rewards - rewards.min()
        weights = r_shifted ** (1.0 / beta)
        weights = weights / weights.sum()
    elif reward_transform == "topk":
        # Top-K ç®€å•è¿‘ä¼¼
        k = int(len(rewards) * topk_ratio)
        topk_indices = torch.topk(rewards, k).indices
        weights = torch.zeros_like(rewards)
        weights[topk_indices] = 1.0 / k

    # åŠ æƒ MLE è®­ç»ƒ
    for epoch in range(num_epochs):
        for batch_idx, (x, y, r) in enumerate(data):
            w = weights[batch_idx].item()

            log_prob = model.log_prob(y, x)
            loss = -w * log_prob

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    return model
```

### 9.4 è¿‘ä¼¼æ–¹æ³•äºŒï¼šè‡ªå½’ä¸€åŒ–é‡è¦æ€§é‡‡æ ·

#### 9.4.1 é—®é¢˜ï¼šå½’ä¸€åŒ–å¸¸æ•°çš„è®¡ç®—

æœ€ä¼˜åˆ†å¸ƒéœ€è¦å½’ä¸€åŒ–å¸¸æ•°ï¼š
$$Z = \sum_y \mu(y|x) \cdot \exp(r(x,y)/\beta)$$

è¿™é€šå¸¸éœ€è¦éå†æ‰€æœ‰å¯èƒ½çš„ yï¼Œè®¡ç®—é‡æå¤§ã€‚

#### 9.4.2 è‡ªå½’ä¸€åŒ–æŠ€å·§

ç”¨æ ·æœ¬å‡å€¼ä»£æ›¿æœŸæœ›ï¼š

$$\hat{\pi}^*(y_i|x) \approx \frac{\mu(y_i|x) \cdot \exp(r_i/\beta)}{\sum_j \mu(y_j|x) \cdot \exp(r_j/\beta)} = \frac{\exp(r_i/\beta)}{\sum_j \exp(r_j/\beta)}$$

**å…³é”®**ï¼š$\mu(y|x)$ åœ¨åˆ†å­åˆ†æ¯ä¸­æŠµæ¶ˆäº†ï¼

æœ€ç»ˆæƒé‡ç®€åŒ–ä¸ºï¼š
$$\hat{w}_i = \text{softmax}(r_i / \beta)$$

#### 9.4.3 å®ç°

```python
def self_normalized_is_training(
    model,
    data_batches,
    beta: float = 1.0,
):
    """
    è‡ªå½’ä¸€åŒ– ISï¼šé¿å…æ˜¾å¼è®¡ç®—å½’ä¸€åŒ–å¸¸æ•°

    æ¯ä¸ª batch å†…ç”¨ softmax(r/Î²) ä½œä¸ºæƒé‡
    """
    for batch in data_batches:
        x_batch, y_batch, r_batch = batch

        # è‡ªå½’ä¸€åŒ–æƒé‡ï¼ˆbatch å†…ï¼‰
        weights = F.softmax(r_batch / beta, dim=0)

        # åŠ æƒå¯¹æ•°ä¼¼ç„¶
        log_probs = model.log_prob(y_batch, x_batch)
        loss = -torch.sum(weights * log_probs)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

### 9.5 è¿‘ä¼¼æ–¹æ³•ä¸‰ï¼šä¸€é˜¶æ³°å‹’å±•å¼€

#### 9.5.1 é€‚ç”¨åœºæ™¯

å½“ç­–ç•¥å˜åŒ–è¾ƒå°æ—¶ï¼ˆ$\pi_\theta \approx \mu$ï¼‰ï¼Œå¯ä»¥ç”¨ä¸€é˜¶è¿‘ä¼¼ã€‚

#### 9.5.2 æ¨å¯¼

è®¾ $\pi_\theta(y|x) = \mu(y|x)(1 + \delta_\theta(y|x))$ï¼Œå…¶ä¸­ $\delta_\theta$ æ˜¯å°æ‰°åŠ¨ã€‚

å½’ä¸€åŒ–çº¦æŸï¼š$\mathbb{E}_\mu[\delta_\theta] = 0$

ä¼˜åŒ–ç›®æ ‡ï¼ˆä¸€é˜¶å±•å¼€ï¼‰ï¼š
$$\max_{\delta} \mathbb{E}_\mu[(1+\delta) \cdot r] - \frac{\beta}{2}\mathbb{E}_\mu[\delta^2/\mu]$$

è¿™æ˜¯å…³äº $\delta$ çš„äºŒæ¬¡ä¼˜åŒ–é—®é¢˜ï¼Œæœ‰é—­å¼è§£ï¼š
$$\delta^*(y|x) = \frac{1}{\beta}(r(y|x) - \bar{r})$$

å…¶ä¸­ $\bar{r} = \mathbb{E}_\mu[r]$ ç¡®ä¿å½’ä¸€åŒ–ã€‚

#### 9.5.3 å¯¹å‚æ•°åŒ–ç­–ç•¥çš„åº”ç”¨

å¦‚æœ $\delta_\theta(y|x) = \theta^T \phi(y,x)$ æ˜¯çº¿æ€§å‚æ•°åŒ–ï¼š

$$\theta^* = \frac{1}{\beta} \mathbb{E}_\mu[\phi(y,x) \cdot r(x,y)]$$

è¿™æ˜¯**å•æ­¥é—­å¼è§£**ï¼

```python
def first_order_closed_form(
    feature_fn,  # Ï†(y, x)
    data,  # [(x_i, y_i, r_i)]
    beta: float = 1.0,
):
    """
    ä¸€é˜¶è¿‘ä¼¼çš„é—­å¼è§£

    é€‚ç”¨äºï¼šçº¿æ€§å‚æ•°åŒ–æˆ–ç‰¹å¾ç©ºé—´
    """
    # è®¡ç®— E[Ï†Â·r]
    features = torch.stack([feature_fn(y, x) for x, y, _ in data])
    rewards = torch.tensor([r for _, _, r in data])

    # ä¸­å¿ƒåŒ–å¥–åŠ±
    rewards_centered = rewards - rewards.mean()

    # é—­å¼è§£
    theta_star = (features.T @ rewards_centered) / (beta * len(data))

    return theta_star
```

### 9.6 è¿‘ä¼¼æ–¹æ³•å››ï¼šå˜åˆ†æ‹Ÿåˆ (Variational Fitting)

#### 9.6.1 æ ¸å¿ƒæ€æƒ³

å°†æœ€ä¼˜åˆ†å¸ƒé™åˆ¶åœ¨æŸä¸ªå‚æ•°åŒ–æ—å†…ï¼Œç„¶åæ‰¾æœ€è¿‘çš„è¿‘ä¼¼ã€‚

è®¾ç›®æ ‡åˆ†å¸ƒä¸º $\pi^* \propto \mu \cdot \exp(r/\beta)$ï¼Œæˆ‘ä»¬æ‰¾ $\pi_\theta$ ä½¿å¾—ï¼š

$$\theta^* = \arg\min_\theta D_{KL}(\pi^* \| \pi_\theta)$$

#### 9.6.2 è½¬åŒ–ä¸ºåŠ æƒ MLE

$$\theta^* = \arg\max_\theta \mathbb{E}_{\pi^*}[\log \pi_\theta] = \arg\max_\theta \mathbb{E}_\mu\left[\frac{\pi^*}{\mu} \log \pi_\theta\right]$$

ç”±äº $\pi^*/\mu \propto \exp(r/\beta)$ï¼š

$$\theta^* = \arg\max_\theta \sum_i \exp(r_i/\beta) \cdot \log \pi_\theta(y_i|x_i)$$

è¿™å°±æ˜¯å¥–åŠ±åŠ æƒå›å½’ï¼ä½†æœ‰æ›´ç²¾ç»†çš„å˜ä½“ã€‚

#### 9.6.3 è¿­ä»£å˜åˆ†æ‹Ÿåˆï¼ˆå°‘é‡è¿­ä»£ï¼‰

```python
def iterative_variational_fitting(
    model,
    data,
    beta: float = 1.0,
    num_iterations: int = 3,  # åªéœ€è¦å°‘é‡è¿­ä»£
):
    """
    è¿­ä»£å˜åˆ†æ‹Ÿåˆï¼šç”¨å°‘é‡è¿­ä»£è¾¾åˆ°æ›´å¥½çš„è¿‘ä¼¼

    å…³é”®ï¼šæ¯æ¬¡è¿­ä»£ç”¨å½“å‰ Ï€_Î¸ æ¥é‡æ–°ä¼°è®¡ç›®æ ‡åˆ†å¸ƒ
    """
    for iteration in range(num_iterations):
        # è®¡ç®—å½“å‰çš„é‡è¦æ€§æƒé‡
        with torch.no_grad():
            log_ratios = []
            for x, y, r in data:
                log_pi = model.log_prob(y, x)
                log_ratios.append(r / beta)  # ç¬¬ä¸€æ¬¡è¿­ä»£ç”¨å¥–åŠ±

        weights = F.softmax(torch.tensor(log_ratios), dim=0)

        # ä¸€è½®åŠ æƒ MLE
        for epoch in range(1):
            for i, (x, y, r) in enumerate(data):
                log_prob = model.log_prob(y, x)
                loss = -weights[i] * log_prob

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

    return model
```

### 9.7 è¿‘ä¼¼æ–¹æ³•äº”ï¼šBest-of-N ä¸ Top-K é‡‡æ ·

#### 9.7.1 æœ€ç®€å•çš„è¿‘ä¼¼

ä¸éœ€è¦è®­ç»ƒï¼Œåªéœ€è¦åœ¨æ¨ç†æ—¶åšé€‰æ‹©ï¼š

1. **Best-of-N (BoN)**ï¼šé‡‡æ · N ä¸ªå“åº”ï¼Œé€‰æ‹©å¥–åŠ±æœ€é«˜çš„
2. **Top-K å¾®è°ƒ**ï¼šåªç”¨å¥–åŠ±æœ€é«˜çš„ K% æ ·æœ¬åš SFT

#### 9.7.2 ç†è®ºè”ç³»

Best-of-N è¿‘ä¼¼çš„åˆ†å¸ƒï¼š
$$\pi_{\text{BoN}}(y|x) \approx \mu(y|x) \cdot N \cdot F_\mu(r(y))^{N-1}$$

å…¶ä¸­ $F_\mu$ æ˜¯å¥–åŠ±çš„ CDFã€‚

**ä¸ IS Reshape çš„è”ç³»**ï¼šå½“ N è¾ƒå¤§æ—¶ï¼ŒBoN è¿‘ä¼¼ mode-seeking è¡Œä¸ºã€‚

#### 9.7.3 å®ç°

```python
def best_of_n_inference(
    model,
    x,
    reward_model,
    n: int = 16,
):
    """Best-of-N æ¨ç†ï¼šé›¶è®­ç»ƒçš„è¿‘ä¼¼"""
    candidates = [model.generate(x) for _ in range(n)]
    rewards = [reward_model(x, y) for y in candidates]
    best_idx = np.argmax(rewards)
    return candidates[best_idx]


def topk_sft(
    model,
    data,  # [(x_i, y_i, r_i)]
    k_ratio: float = 0.2,
):
    """Top-K SFTï¼šåªåœ¨æœ€å¥½çš„æ ·æœ¬ä¸Šè®­ç»ƒ"""
    # é€‰æ‹© top K% æ ·æœ¬
    rewards = [r for _, _, r in data]
    threshold = np.percentile(rewards, 100 * (1 - k_ratio))
    filtered_data = [(x, y, r) for x, y, r in data if r >= threshold]

    # æ ‡å‡† SFT
    for x, y, _ in filtered_data:
        log_prob = model.log_prob(y, x)
        loss = -log_prob

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    return model
```

### 9.8 æ–¹æ³•å¯¹æ¯”ä¸é€‰æ‹©æŒ‡å—

| æ–¹æ³• | è®¡ç®—å¤æ‚åº¦ | è¿‘ä¼¼ç²¾åº¦ | é€‚ç”¨åœºæ™¯ |
|-----|-----------|---------|---------|
| **å¥–åŠ±åŠ æƒå›å½’** | O(1) è®­ç»ƒè½® | ä¸­ç­‰ | æœ‰æ˜ç¡®å¥–åŠ±ï¼Œæ•°æ®è´¨é‡é«˜ |
| **è‡ªå½’ä¸€åŒ– IS** | O(1) è®­ç»ƒè½® | ä¸­ç­‰-é«˜ | æ‰¹é‡æ•°æ®å¯ç”¨ |
| **ä¸€é˜¶é—­å¼è§£** | O(1) è®¡ç®— | ä½ï¼ˆ$\pi \approx \mu$ï¼‰ | å¾®è°ƒåœºæ™¯ï¼Œå˜åŒ–å° |
| **å˜åˆ†æ‹Ÿåˆ** | O(k) è¿­ä»£ï¼Œk å° | é«˜ | éœ€è¦æ›´ç²¾ç¡®çš„è¿‘ä¼¼ |
| **Best-of-N** | æ¨ç†æ—¶ O(N) | ä¾èµ– N | æ— æ³•å¾®è°ƒæ—¶ |
| **Top-K SFT** | O(1) è®­ç»ƒè½® | ä¸­ç­‰ | æœ€ç®€å•ï¼Œæ•°æ®é‡å¤§ |

### 9.9 å®è·µå»ºè®®

#### 9.9.1 ä½•æ—¶ç”¨ç›´æ¥æ–¹æ³• vs è¿­ä»£æ–¹æ³•

**ä½¿ç”¨ç›´æ¥æ–¹æ³•**ï¼š
- Offline åœºæ™¯ï¼Œæ— æ³•ä¸ç¯å¢ƒäº¤äº’
- è®¡ç®—èµ„æºæœ‰é™ï¼Œåªèƒ½åšå°‘é‡è®­ç»ƒ
- åˆæ­¥å¿«é€Ÿå®éªŒï¼ŒéªŒè¯æ–¹å‘
- æ•°æ®è´¨é‡é«˜ï¼Œå¥–åŠ±ä¿¡å·æ¸…æ™°

**ä½¿ç”¨è¿­ä»£æ–¹æ³•**ï¼š
- éœ€è¦ç²¾ç¡®æ§åˆ¶ç­–ç•¥å˜åŒ–
- åˆ†å¸ƒåç§»ä¸¥é‡ï¼Œéœ€è¦å¤šæ­¥è°ƒæ•´
- æœ‰åœ¨çº¿äº¤äº’çš„å¯èƒ½
- å¯¹æœ€ç»ˆæ€§èƒ½è¦æ±‚é«˜

#### 9.9.2 æ¸©åº¦å‚æ•° Î² çš„é€‰æ‹©

```python
def adaptive_beta(rewards, target_ess_ratio=0.3):
    """
    æ ¹æ® ESS è‡ªé€‚åº”é€‰æ‹© Î²

    æ€è·¯ï¼šÎ² æ§åˆ¶æƒé‡çš„é›†ä¸­ç¨‹åº¦
    - Î² å¤§ â†’ æƒé‡æ›´å‡åŒ€
    - Î² å° â†’ æƒé‡æ›´é›†ä¸­åœ¨é«˜å¥–åŠ±æ ·æœ¬
    """
    def compute_ess_ratio(beta):
        weights = F.softmax(torch.tensor(rewards) / beta, dim=0)
        ess = 1.0 / (weights ** 2).sum()
        return ess / len(rewards)

    # äºŒåˆ†æœç´¢
    beta_low, beta_high = 0.01, 10.0
    for _ in range(20):
        beta_mid = (beta_low + beta_high) / 2
        if compute_ess_ratio(beta_mid) >= target_ess_ratio:
            beta_high = beta_mid
        else:
            beta_low = beta_mid

    return beta_mid
```

#### 9.9.3 ä¸ IS Reshape çš„ç»Ÿä¸€è§†è§’

æ‰€æœ‰ç›´æ¥æ–¹æ³•éƒ½å¯ä»¥ç†è§£ä¸º IS Reshape çš„ç‰¹ä¾‹æˆ–è¿‘ä¼¼ï¼š

| ç›´æ¥æ–¹æ³• | IS Reshape è§†è§’ |
|---------|----------------|
| æŒ‡æ•°åŠ æƒ RWR | f(w) = 1ï¼Œä½†éšå¼å¼•å…¥äº† exp(r/Î²) å˜æ¢ |
| Top-K SFT | f(w) = ğŸ™[w âˆˆ top-K]ï¼Œç¡¬æˆªæ–­ |
| ä¸€é˜¶è¿‘ä¼¼ | f(w) â‰ˆ 1 + Î³(w-1)ï¼Œçº¿æ€§åŒ– |
| BoN | éšå¼çš„ f(w) = w^(N-1)Â·N |

---

## 10. æ€»ç»“

### 10.1 æ ¸å¿ƒæ´è§

1. **ä¼ ç»Ÿ SFT çš„é—®é¢˜**ï¼šForward KL çš„ mean-seeking ç‰¹æ€§å¯¼è‡´æ¨¡å‹è¢«è¿«è¦†ç›–æ‰€æœ‰æ¨¡å¼ï¼Œå¼•å‘ç¾éš¾æ€§é—å¿˜

2. **IS Reshape çš„è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡ f(w) = w^Î³ åŠ æƒï¼Œå°†ä¼˜åŒ–ä» mean-seeking è½¬å‘ mode-seeking

3. **å®è·µæ„ä¹‰**ï¼šä¼˜å…ˆå­¦ä¹ ä¸å½“å‰æ¨¡å‹æ¥è¿‘çš„æ¨¡å¼ï¼Œæœ€å°åŒ–å‚æ•°å˜åŒ–ï¼Œä¿æŠ¤å·²æœ‰èƒ½åŠ›

4. **ç†è®ºä¿è¯**ï¼šÎ³ çš„é€‰æ‹©æœ‰ç†è®ºæŒ‡å¯¼ï¼ˆBias-Variance æƒè¡¡ï¼‰ï¼Œå¯é€šè¿‡ ESS è‡ªé€‚åº”è°ƒæ•´

5. **Sequence vs Token Level**ï¼šToken-level ç›®æ ‡æ˜¯ sequence-level ç›®æ ‡çš„ä¸€é˜¶è¿‘ä¼¼ï¼Œå½“ $\pi_\theta \approx \mu$ æ—¶è¿‘ä¼¼æœ‰æ•ˆ

6. **ç›´æ¥æ±‚è§£æ–¹æ³•**ï¼šé€šè¿‡å¥–åŠ±åŠ æƒå›å½’ã€è‡ªå½’ä¸€åŒ– IS ç­‰æŠ€æœ¯ï¼Œå¯ä»¥é¿å…è¿­ä»£æ±‚è§£ï¼Œå®ç°è¿‘ä¼¼ç›´æ¥ä¼˜åŒ–

### 10.2 å…¬å¼æ€»ç»“

**Mode-Seeking SFT æŸå¤±**ï¼š
$$L_\gamma(\theta) = -\sum_i \bar{w}_i^\gamma \cdot \log \pi_\theta(y_i|x_i)$$

å…¶ä¸­ï¼š
$$\bar{w}_i = \frac{\pi_\theta(y_i|x_i)}{\pi_0(y_i|x_i)}, \quad \gamma \in [0, 1]$$

**Î³ çš„ä½œç”¨**ï¼š
- Î³ = 0ï¼šä¼ ç»Ÿ SFTï¼ˆmean-seekingï¼‰
- Î³ > 0ï¼šMode-seekingï¼Œèšç„¦äºè¿‘æ¨¡å¼
- Î³ = 1ï¼šçº¯è‡ªæˆ‘å¼ºåŒ–ï¼ˆä¸æ¨èï¼‰

### 10.3 å®è·µ Checklist

- [ ] ä¿å­˜åˆå§‹æ¨¡å‹ $\pi_0$ ä½œä¸ºå‚è€ƒ
- [ ] å®ç° IS æƒé‡è®¡ç®—ï¼š$w = \pi_\theta / \pi_0$
- [ ] å®ç°è‡ªé€‚åº” Î³ é€‰æ‹©ï¼ˆåŸºäº ESSï¼‰
- [ ] ç›‘æ§ ESS æ¯”ä¾‹ï¼Œç¡®ä¿åœ¨åˆç†èŒƒå›´
- [ ] ç›‘æ§ token-level $\delta_t$ çš„å¤§å°ï¼Œç¡®ä¿ä¸€é˜¶è¿‘ä¼¼æœ‰æ•ˆ
- [ ] åœ¨æ—§ä»»åŠ¡ä¸ŠéªŒè¯æ€§èƒ½ä¿æŒ
- [ ] è€ƒè™‘ä¸ LoRA/KL æ­£åˆ™åŒ–ç»“åˆ
- [ ] å¯¹äº MoE æ¨¡å‹ï¼Œè€ƒè™‘ä½¿ç”¨ Routing Replay
- [ ] **ï¼ˆæ–°å¢ï¼‰** è¯„ä¼°æ˜¯å¦å¯ä»¥ä½¿ç”¨ç›´æ¥æ±‚è§£æ–¹æ³•ï¼ˆå¥–åŠ±åŠ æƒå›å½’ã€Top-K SFTï¼‰
- [ ] **ï¼ˆæ–°å¢ï¼‰** æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¸©åº¦å‚æ•° Î²ï¼ˆæˆ–ä½¿ç”¨è‡ªé€‚åº”æ–¹æ³•ï¼‰
- [ ] **ï¼ˆæ–°å¢ï¼‰** å¯¹äº offline åœºæ™¯ï¼Œä¼˜å…ˆè€ƒè™‘è‡ªå½’ä¸€åŒ– IS æˆ–å˜åˆ†æ‹Ÿåˆ

---

## é™„å½•ï¼šPyTorch å®ç°

```python
import torch
import torch.nn.functional as F
from typing import Optional, Tuple

class ModeSeeking SFTTrainer:
    """
    Mode-Seeking SFT: ä» IS Reshape è§†è§’ä¼˜åŒ–çš„ SFT

    æ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡ w^Î³ åŠ æƒï¼Œä¼˜å…ˆå­¦ä¹ ä¸å½“å‰æ¨¡å‹æ¥è¿‘çš„æ¨¡å¼
    """

    def __init__(
        self,
        model: torch.nn.Module,
        ref_model: torch.nn.Module,  # å†»ç»“çš„å‚è€ƒæ¨¡å‹
        gamma: Optional[float] = None,  # None åˆ™è‡ªé€‚åº”
        rho_min: float = 0.3,  # ESS çº¦æŸ
        kl_coef: float = 0.0,  # å¯é€‰çš„ KL æ­£åˆ™åŒ–
    ):
        self.model = model
        self.ref_model = ref_model
        self.gamma = gamma
        self.rho_min = rho_min
        self.kl_coef = kl_coef

        # å†»ç»“å‚è€ƒæ¨¡å‹
        for param in self.ref_model.parameters():
            param.requires_grad = False

    def compute_loss(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor,
        labels: torch.Tensor,
    ) -> Tuple[torch.Tensor, dict]:
        """
        è®¡ç®— Mode-Seeking SFT æŸå¤±
        """
        # å½“å‰æ¨¡å‹çš„ log prob
        outputs = self.model(input_ids, attention_mask=attention_mask)
        log_probs = self._compute_log_probs(outputs.logits, labels)

        # å‚è€ƒæ¨¡å‹çš„ log prob
        with torch.no_grad():
            ref_outputs = self.ref_model(input_ids, attention_mask=attention_mask)
            ref_log_probs = self._compute_log_probs(ref_outputs.logits, labels)

        # è®¡ç®— log é‡è¦æ€§æƒé‡
        log_w = log_probs - ref_log_probs

        # è‡ªé€‚åº”é€‰æ‹© Î³
        if self.gamma is None:
            gamma = self._adaptive_gamma(log_w.detach())
        else:
            gamma = self.gamma

        # è®¡ç®—å½’ä¸€åŒ–æƒé‡ï¼ˆæ•°å€¼ç¨³å®šï¼‰
        weights = F.softmax(gamma * log_w.detach(), dim=0)

        # Mode-Seeking SFT æŸå¤±
        loss = -torch.sum(weights * log_probs)

        # å¯é€‰ï¼šKL æ­£åˆ™åŒ–
        if self.kl_coef > 0:
            kl_div = torch.mean(log_probs - ref_log_probs)
            loss = loss + self.kl_coef * kl_div

        # è®¡ç®—ç›‘æ§æŒ‡æ ‡
        ess = 1.0 / torch.sum(weights ** 2)
        metrics = {
            'gamma': gamma,
            'ess': ess.item(),
            'ess_ratio': ess.item() / len(log_w),
            'max_weight': weights.max().item(),
            'mean_log_w': log_w.mean().item(),
            'std_log_w': log_w.std().item(),
        }

        return loss, metrics

    def _compute_log_probs(
        self,
        logits: torch.Tensor,
        labels: torch.Tensor
    ) -> torch.Tensor:
        """è®¡ç®—æ¯ä¸ªåºåˆ—çš„ log probability"""
        # Shift for causal LM
        shift_logits = logits[..., :-1, :].contiguous()
        shift_labels = labels[..., 1:].contiguous()

        # è®¡ç®— token çº§åˆ«çš„ log prob
        log_probs = F.log_softmax(shift_logits, dim=-1)
        token_log_probs = torch.gather(
            log_probs,
            dim=-1,
            index=shift_labels.unsqueeze(-1)
        ).squeeze(-1)

        # å¯¹æœ‰æ•ˆ token æ±‚å’Œï¼ˆå¿½ç•¥ paddingï¼‰
        mask = (shift_labels != -100).float()
        seq_log_probs = (token_log_probs * mask).sum(dim=-1)

        return seq_log_probs

    def _adaptive_gamma(self, log_w: torch.Tensor) -> float:
        """åŸºäº ESS çº¦æŸè‡ªé€‚åº”é€‰æ‹© Î³"""
        n = len(log_w)

        def compute_ess_ratio(gamma):
            weights = F.softmax(gamma * log_w, dim=0)
            ess = 1.0 / torch.sum(weights ** 2)
            return (ess / n).item()

        # äºŒåˆ†æœç´¢
        gamma_low, gamma_high = 0.0, 2.0
        for _ in range(20):
            gamma_mid = (gamma_low + gamma_high) / 2
            if compute_ess_ratio(gamma_mid) >= self.rho_min:
                gamma_low = gamma_mid
            else:
                gamma_high = gamma_mid

        return gamma_low


# ä½¿ç”¨ç¤ºä¾‹
def train_mode_seeking_sft(
    model,
    ref_model,
    train_dataloader,
    optimizer,
    num_epochs=3,
    rho_min=0.3,
):
    trainer = ModeSeekingSFTTrainer(
        model=model,
        ref_model=ref_model,
        gamma=None,  # è‡ªé€‚åº”
        rho_min=rho_min,
    )

    for epoch in range(num_epochs):
        total_loss = 0
        total_gamma = 0
        total_ess_ratio = 0
        num_batches = 0

        for batch in train_dataloader:
            loss, metrics = trainer.compute_loss(
                batch['input_ids'],
                batch['attention_mask'],
                batch['labels'],
            )

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_gamma += metrics['gamma']
            total_ess_ratio += metrics['ess_ratio']
            num_batches += 1

        print(f"Epoch {epoch+1}: "
              f"Loss={total_loss/num_batches:.4f}, "
              f"Î³={total_gamma/num_batches:.3f}, "
              f"ESS_ratio={total_ess_ratio/num_batches:.3f}")
```
